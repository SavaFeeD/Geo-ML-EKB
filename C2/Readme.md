# Task 1: Create new feature (index_)

> index_ = h_address * most_common_severity_region / h_region

Добавил новую фичу назвал ее index_ и заполнил его индексом который вычислил для каждого ДТП

# Task 2: Clustering

Для выбора модели я буду использовать две метрики:
1. Индекс Калинского-Харабаза (синие графики) - чем выше показатель тем лучше
2. Индекс Дэвиса болдина (оранжевые графики) - в идеале должен стремиться к нулю (0 = идельно)

Исходя из этих двух метрик которые я проверил на одинаковом наборе данных для всех моделей (KMeans, GaussianMixture, MiniBatchKMeans) показатели для разного кол-ва кластеров.
В виду того что необходимо четкое кол-во кластеро (три) то по всем показателям метрик лучше всего себя показывает модель кластеризации MiniBatchKMeans

Я выбираю модель MiniBatchKMeans для распределения ДТП по кластерам

Даем названия кластерам исходя из распределения данных

1. 'Без угроз для здоровья'
2. 'Угроза здоровью'
3. 'Максимальная опасность'

# Task 3: Train & Test split dataset

Перемешать датасет чтобы было разнообразнее

Разделить на целевую переменную и данные

Разбить датасет на тестовую и обучающую выборки

# Task 4: Export datasets

Файлы в Data.zip:

1. dataframe.csv - полностью собраный и предобработанный датасет
2. labeling.pkl - словарь содержащий кодер и декодер некоторых фич
3. train_df.csv - выборка для обучения
4. test_df.csv - выборка для тестирования